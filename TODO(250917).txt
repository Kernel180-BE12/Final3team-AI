# JOBER_AI 기본 기능 완성도 향상 TODO 리스트
## 현재 성공률: 30% → 목표: 85%+

📅 작성일: 2025-09-17
🎯 목표: 템플릿 분류 정확도 및 API 안정성 개선

---

## 🔥 우선순위 1: 템플릿 분류 정확도 개선 (Critical)

### 1.1 템플릿 매칭 로직 수정
- [ ] **파일**: `src/core/template_selector.py`
- [ ] **문제**: reject 케이스가 approve로 잘못 분류됨 (현재 테스트 결과)
- [ ] **작업**:
  - [ ] BasicTemplateMatcher 의 유사도 임계값 (0.85) 조정
  - [ ] 키워드 가중치 기반 매칭으로 변경
  - [ ] 템플릿 관련성 검증 로직 추가
  - [ ] 입력 복잡도에 따른 동적 임계값 구현

### 1.2 변수 형식 통일
- [ ] **파일**: `src/core/template_generator.py`, `template_selector.py`
- [ ] **문제**: `#{variable}`과 `${variable}` 혼재 사용
- [ ] **작업**:
  - [ ] 모든 템플릿을 `${variable}` 형식으로 통일
  - [ ] `_standardize_variables()` 함수 수정
  - [ ] 기존 템플릿 데이터 변환 스크립트 작성

### 1.3 Public Template Manager 개선
- [ ] **파일**: `src/core/public_template_manager.py`
- [ ] **문제**: SequenceMatcher 사용으로 인한 부정확한 매칭
- [ ] **작업**:
  - [ ] SequenceMatcher를 의미 기반 유사도로 교체
  - [ ] 상반된 의도 감지 기능 추가
  - [ ] 카테고리 기반 사전 필터링 구현

---

## ⚡ 우선순위 2: API 안정성 및 오류 처리 개선 (High)

### 2.1 Rate Limiting 버그 수정 ⚠️ **즉시 수정 가능**
- [ ] **파일**: `server.py` (라인 67, 102-117)
- [ ] **문제**: 메모리 기반 카운터로 인한 심각한 버그들
- [ ] **발견된 버그들**:
  - [ ] **메모리 누수**: `request_counts = defaultdict(list)` 무한 증가
  - [ ] **동시성 문제**: race condition으로 정확한 카운팅 불가
  - [ ] **서버 재시작 시 초기화**: 제한 카운터 리셋으로 악용 가능
  - [ ] **스케일링 불가**: 여러 서버 인스턴스 간 공유 불가

#### 🛠️ **즉시 수정 방법 (20분 소요)**

##### **Step 1: 메모리 누수 수정 (5분)**
```python
# server.py 상단에 추가 (라인 10 근처)
import threading
from datetime import datetime, timedelta

# 기존 코드 수정
rate_limit_lock = threading.Lock()  # 동시성 보호
last_cleanup_time = time.time()     # 마지막 정리 시간
CLEANUP_INTERVAL = 300              # 5분마다 정리
```

##### **Step 2: 메모리 정리 함수 추가 (10분)**
```python
# check_rate_limit 함수 위에 추가 (라인 102 전)
def cleanup_old_requests():
    """오래된 요청 기록 정리하여 메모리 누수 방지"""
    global last_cleanup_time
    current_time = time.time()

    # 5분마다만 정리 실행
    if current_time - last_cleanup_time < CLEANUP_INTERVAL:
        return

    with rate_limit_lock:
        # 모든 사용자의 오래된 요청 제거
        for user_id in list(request_counts.keys()):
            request_counts[user_id] = [
                req_time for req_time in request_counts[user_id]
                if current_time - req_time < RATE_LIMIT_WINDOW
            ]
            # 빈 리스트면 사용자 기록 완전 삭제
            if not request_counts[user_id]:
                del request_counts[user_id]

        last_cleanup_time = current_time
        print(f"🧹 Rate limit 메모리 정리 완료: {len(request_counts)}명 활성 사용자")
```

##### **Step 3: 동시성 보호 적용 (5분)**
```python
# 기존 check_rate_limit 함수 전체 교체 (라인 102-117)
def check_rate_limit(user_id: int) -> bool:
    """사용자별 요청 제한 확인 (동시성 보호 + 메모리 누수 방지)"""

    # 주기적 메모리 정리
    cleanup_old_requests()

    current_time = time.time()

    with rate_limit_lock:  # 동시성 보호
        user_requests = request_counts[user_id]

        # 1분 이전 요청들 제거
        valid_requests = [
            req_time for req_time in user_requests
            if current_time - req_time < RATE_LIMIT_WINDOW
        ]
        request_counts[user_id] = valid_requests

        # 현재 요청 수 확인
        if len(valid_requests) >= RATE_LIMIT_PER_MINUTE:
            print(f"🚫 Rate limit 초과: user_id={user_id}, 요청수={len(valid_requests)}")
            return False

        # 현재 요청 추가
        request_counts[user_id].append(current_time)
        print(f"✅ Rate limit 통과: user_id={user_id}, 요청수={len(valid_requests)+1}")
        return True
```

#### 🧪 **테스트 방법**
```bash
# 1. 동시 요청 테스트
for i in {1..15}; do
  curl -X POST "http://127.0.0.1:8000/ai/templates" \
    -H "Content-Type: application/json" \
    -d '{"userId": 999, "requestContent": "테스트 메시지 '$i'"}' &
done
wait

# 2. 메모리 사용량 모니터링
ps aux | grep "python server.py" | awk '{print $6 " KB"}'
```

#### 📊 **개선 효과**
- ✅ **메모리 누수 해결**: 장시간 실행해도 메모리 안정
- ✅ **동시성 안전**: 멀티스레드 환경에서 정확한 카운팅
- ✅ **성능 향상**: 주기적 정리로 조회 속도 개선
- ✅ **로깅 추가**: 디버깅 및 모니터링 가능

- [ ] **장기 작업 (향후)**:
  - [ ] Redis 기반 또는 파일 기반 지속성 구현
  - [ ] 환경별 설정 분리 (dev vs prod)
  - [ ] 분산 환경 지원

### 2.2 언어 감지 기능 추가
- [ ] **파일**: 새로 생성 `src/utils/language_detector.py`
- [ ] **문제**: 영어 입력에 한국어 템플릿 생성
- [ ] **작업**:
  - [ ] 한국어 텍스트 비율 감지 구현
  - [ ] 비한국어 입력에 대한 조기 거부
  - [ ] 도움이 되는 오류 메시지 제공

### 2.3 오류 처리 표준화
- [ ] **파일**: `server.py`, `api.py`
- [ ] **문제**: 일관성 없는 오류 응답 형식
- [ ] **작업**:
  - [ ] 통합 오류 응답 형식 생성
  - [ ] 각 실패 유형별 적절한 오류 코드 추가
  - [ ] 구조화된 로깅 구현

---

## 🔧 우선순위 3: 핵심 처리 파이프라인 최적화 (Medium)

### 3.1 Agent1 개선
- [ ] **파일**: `src/agents/agent1.py`
- [ ] **문제**: 변수 추출 불일치, 의도 분류 정확도 낮음
- [ ] **작업**:
  - [ ] 변수 추출 정확도 향상
  - [ ] 컨텍스트 인식 의도 분류 구현
  - [ ] 정책 위반 false positive 감소

### 3.2 Agent2 도구 조정
- [ ] **파일**: `src/agents/agent2.py`
- [ ] **문제**: 4가지 도구(BlackList/WhiteList/Guideline/Law) 통합 이슈
- [ ] **작업**:
  - [ ] 4-tool 결과 통합 로직 수정
  - [ ] 검증 가중치 조정 (현재: blacklist 35%, law 30%, guideline 25%, whitelist 10%)
  - [ ] 점진적 수정으로 재생성 로직 개선

### 3.3 Template Validator 강화
- [ ] **파일**: `src/core/template_validator.py`
- [ ] **문제**: 단순한 점수 체계
- [ ] **작업**:
  - [ ] 더 세밀한 점수 체계 구현
  - [ ] 비즈니스 로직 검증 추가
  - [ ] 지속적 개선을 위한 피드백 루프 생성

---

## 📊 우선순위 4: 데이터 품질 및 성능 개선 (Medium)

### 4.1 데이터 로딩 최적화
- [ ] **파일**: `src/core/index_manager.py`
- [ ] **문제**: predata 캐시 미스로 인한 성능 저하
- [ ] **작업**:
  - [ ] 효율적인 predata 캐싱 구현
  - [ ] 캐시 무효화 전략 추가
  - [ ] 중복 파일 I/O 작업 감소

### 4.2 템플릿 품질 개선
- [ ] **파일**: 새로 생성할 품질 관리 시스템
- [ ] **작업**:
  - [ ] 템플릿 관련성 점수 시스템 생성
  - [ ] 사용자 피드백 통합 시스템
  - [ ] 개선을 위한 A/B 테스트 프레임워크

---

## 🧪 테스트 및 검증

### 5.1 현재 진행 중인 테스트
- [x] **CSV 전체 데이터 테스트 실행 중** (508개 케이스, 예상 101분)
- [ ] 테스트 결과 분석 및 문제점 파악
- [ ] 개선 후 재테스트

### 5.2 추가 테스트 계획
- [ ] 단위 테스트 작성 (각 컴포넌트별)
- [ ] 통합 테스트 구축
- [ ] 성능 테스트 (응답 시간, 처리량)
- [ ] 스트레스 테스트 (API 한계 테스트)

---

## 📈 성과 목표

### 현재 상황 (2025-09-17)
- ❌ **전체 성공률**: 30%
- ❌ **반료 케이스 정확도**: 0% (모두 잘못 승인됨)
- ✅ **승인 케이스 정확도**: 60%
- ❌ **API 오류율**: ~40%

### 목표 성과 (개선 후)
- 🎯 **전체 성공률**: 85%+
- 🎯 **반료 케이스 정확도**: 90%+
- 🎯 **승인 케이스 정확도**: 95%+
- 🎯 **API 오류율**: <5%
- 🎯 **평균 응답 시간**: <3초
- 🎯 **처리 성공률**: 85%+

---

## 📅 구현 일정

### Week 1-2: Critical Issues (우선순위 1 & 2)
- [ ] 템플릿 매칭 로직 수정
- [ ] 변수 형식 통일
- [ ] Rate limiting 버그 수정
- [ ] 오류 처리 표준화

### Week 3-4: Core Processing (우선순위 3)
- [ ] Agent1 개선
- [ ] Agent2 도구 조정
- [ ] Template Validator 강화

### Week 5-6: Quality & Performance (우선순위 4)
- [ ] 데이터 로딩 최적화
- [ ] 템플릿 품질 개선
- [ ] 성능 튜닝

### Week 7: Testing & Deployment
- [ ] 전체 시스템 테스트
- [ ] 성능 검증
- [ ] 운영 배포

---

## 🔍 핵심 파일 위치

### 수정이 필요한 주요 파일
1. **`/Users/david/Documents/study/Jober_ai/src/core/template_selector.py`** - 템플릿 매칭 로직
2. **`/Users/david/Documents/study/Jober_ai/server.py`** - Rate limiting 및 오류 처리
3. **`/Users/david/Documents/study/Jober_ai/src/agents/agent1.py`** - 변수 추출 및 검증
4. **`/Users/david/Documents/study/Jober_ai/src/core/template_validator.py`** - 검증 점수
5. **`/Users/david/Documents/study/Jober_ai/src/core/public_template_manager.py`** - 템플릿 매칭 정확도

### 새로 생성할 파일
1. **`src/utils/language_detector.py`** - 언어 감지
2. **`src/utils/error_handler.py`** - 통합 오류 처리
3. **`src/core/quality_manager.py`** - 품질 관리 시스템

---

## 💡 참고사항

### 현재 CSV 테스트 진행 상황
- **시작 시간**: 15:23 (예상 종료: 17:04)
- **총 케이스**: 508개 (반료 59개 + 승인 449개)
- **API 보호 대기**: 12초/케이스
- **결과 파일**: `csv_comprehensive_test_results.csv`, `csv_comprehensive_test_report.json`

### 다음 작업 우선순위
1. CSV 테스트 완료 대기 및 결과 분석
2. 가장 시급한 템플릿 매칭 로직 수정부터 시작
3. 점진적으로 각 우선순위별 작업 진행

---
⚠️ **주의**: 모든 변경사항은 기존 기능을 깨뜨리지 않도록 단계적으로 진행하고, 각 단계마다 테스트를 실시할 것.

✅ **성공 지표**: 다음 CSV 테스트에서 85% 이상 성공률 달성

### 3. LangChain LCEL + RunnableParallel 적용 분석

#### 현재 Agent2 구조 분석
```python
# src/agents/agent2.py - 현재 순차 처리
tools_results = await self._run_tools_parallel(user_input)
blacklist_result = tools_results["blacklist"]
whitelist_result = tools_results["whitelist"] 
guideline_result = tools_results["guideline"]
law_result = tools_results["law"]
```

#### LCEL 체인 구성으로 개선 가능
```python
from langchain.schema.runnable import RunnableParallel, RunnableLambda

# 4개 Tools를 RunnableParallel로 병렬 실행
parallel_tools = RunnableParallel(
    blacklist=RunnableLambda(lambda x: self.blacklist_tool.run(x)),
    whitelist=RunnableLambda(lambda x: self.whitelist_tool.run(x)), 
    guideline=RunnableLambda(lambda x: self.guideline_tool.run(x)),
    law=RunnableLambda(lambda x: self.law_tool.run(x))
)

# LCEL 체인 구성
chain = (
    parallel_tools |  # 4개 툴 병렬 실행
    RunnableLambda(lambda results: self._generate_final_template(results)) |
    RunnableLambda(lambda template: self._post_process(template))
)

# 비동기 실행
result = await chain.ainvoke(user_input)
```

#### RunnableParallel 적용 효과
**Before**: BlackList(1초) → WhiteList(1초) → Guideline(1초) → Law(1초) = 4초
**After**: 4개 Tool 동시 실행 = 1초 (가장 느린 Tool 기준)

### 5. Celery 분산 작업 큐

#### Celery 도입 시나리오
```python
@app.task
def generate_template_task(user_input, user_id):
    result = template_api.generate_template(user_input)
    return result

# 비동기 작업 큐잉
@app.post("/ai/templates")
async def create_template(request):
    task = generate_template_task.delay(request.content, request.user_id)
    return {"task_id": task.id, "status": "processing"}
```
**장점**: 완전 분산 처리, 큐 기반 로드밸런싱, 실패 재시도
**단점**: Redis/RabbitMQ 필요, 복잡한 인프라, 실시간 응답 불가

### 7. LCEL 체인 구성 상세 설계

#### Agent2 LCEL 체인 재구성
```python
# 현재 순차 처리를 LCEL 병렬 체인으로 변환
agent2_chain = (
    # 1. 입력 전처리
    RunnableLambda(lambda x: self._preprocess_input(x)) |
    
    # 2. 4개 Tools 병렬 실행 (핵심 개선점)
    RunnableParallel(
        blacklist=blacklist_tool,
        whitelist=whitelist_tool, 
        guideline=guideline_tool,
        law=law_tool
    ) |
    
    # 3. 결과 통합 및 템플릿 생성
    RunnableLambda(lambda results: self._combine_results(results)) |
    
    # 4. LLM 템플릿 생성
    ChatGoogleGenerativeAI(model="gemini-2.0-flash-exp") |
    
    # 5. 후처리
    RunnableLambda(lambda output: self._post_process(output))
)

# 비동기 실행
result = await agent2_chain.ainvoke(user_input)
```