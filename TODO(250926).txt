# JOBER_AI 개선 계획 - 2024.09.26

## 🚨 URGENT: 성능 최적화 (10-20초 → 5-10초)

### 현재 문제상황
- **템플릿 생성 시간**: 10-20초 (목표: 5-10초)
- **주요 병목지점**:
  - Agent1 순차 처리: 2-5초 (25-30%)
  - Agent2 순차 처리: 8-15초 (60-70%)
  - 기타 DB/네트워크: 0.5-2초 (5-15%)

### 🎯 핵심 성능 최적화 전략

#### Phase 1: 즉시 개선 (1-2주) - 40% 성능 향상
1. **Agent2 도구 병렬화** ⭐ **절약: 2-3초**
   ```python
   # 현재: 순차 실행 (4초)
   blacklist_result = blacklist_tool.invoke(input_data)  # 1s
   whitelist_result = whitelist_tool.invoke(input_data)  # 1s
   guideline_result = guideline_tool.invoke(input_data)  # 1s
   law_result = law_tool.invoke(input_data)             # 1s

   # 최적화: 병렬 실행 (1.5초)
   tasks = [
       asyncio.to_thread(blacklist_tool.invoke, input_data),
       asyncio.to_thread(whitelist_tool.invoke, input_data),
       asyncio.to_thread(guideline_tool.invoke, input_data),
       asyncio.to_thread(law_tool.invoke, input_data)
   ]
   results = await asyncio.gather(*tasks)
   ```

2. **Agent1 병렬 처리** ⭐ **절약: 3-4초**
   ```python
   # 현재: 순차 실행 (3초)
   variables = await variable_extractor.extract_variables_async(user_input)
   intent = await intent_classifier.classify_intent_async(user_input)

   # 최적화: 병렬 실행 (1.5초)
   tasks = [
       variable_extractor.extract_variables_async(user_input),
       intent_classifier.classify_intent_async(user_input),
       profanity_checker.check_text_async(user_input)
   ]
   variables, intent, profanity = await asyncio.gather(*tasks)
   ```

3. **LLM 연결 풀링** ⭐ **절약: 0.5-1초**
   ```python
   class OptimizedLLMManager:
       def __init__(self):
           self.connection_pool = aiohttp.TCPConnector(
               limit=10, limit_per_host=5, keepalive_timeout=30
           )
           self.session = aiohttp.ClientSession(connector=self.connection_pool)
   ```

**Phase 1 예상 결과**: 15-20초 → 8-12초 (40% 개선)

#### Phase 2: 목표 달성 (2-4주) - 60% 성능 향상
1. **고급 LLM 최적화**
   - 프롬프트 압축: 토큰 수 30% 감소
   - 요청 배치: 호환 가능한 요청 결합
   - 응답 캐싱: 자주 사용되는 패턴 캐시

2. **템플릿 캐싱 시스템**
   ```python
   class CachedToolManager:
       def __init__(self):
           self.cache = TTLCache(maxsize=1000, ttl=3600)  # 1시간 캐시

       async def get_tool_results(self, user_input: str):
           cache_key = hashlib.md5(user_input.encode()).hexdigest()
           if cache_key in self.cache:
               return self.cache[cache_key]
   ```

3. **Chroma DB 비동기 최적화**

**Phase 2 예상 결과**: 8-12초 → 5-8초 (60% 개선, 목표 달성)

#### Phase 3: 우수성 달성 (1-2개월) - 70% 성능 향상
1. **지능형 캐싱**: ML 기반 캐시 예측
2. **스트리밍 응답**: 부분 결과 실시간 전송
3. **로드 밸런싱**: 다중 LLM 제공자 균형

### 🔧 구체적 구현 계획

#### 우선순위 1: Agent2 도구 병렬화 (즉시 시작)
- **파일**: `app/agents/agent2.py`
- **메서드**: `generate_compliant_template_async()`
- **예상 시간**: 2-3일
- **예상 효과**: 2-3초 단축

#### 우선순위 2: Agent1 병렬 처리
- **파일**: `app/agents/agent1.py`
- **메서드**: `process_query()`, `extract_variables_and_classify_intent()`
- **예상 시간**: 3-5일
- **예상 효과**: 3-4초 단축

#### 우선순위 3: LLM 관리자 최적화
- **파일**: `app/utils/llm_provider_manager.py`
- **구현**: 연결 풀, 배치 처리, 캐싱
- **예상 시간**: 1주
- **예상 효과**: 1-2초 단축

### 📊 성능 모니터링 지표
- **목표**: 전체 응답 시간 5-10초
- **Agent1 처리 시간**: <2초
- **Agent2 처리 시간**: <5초
- **LLM 호출 지연**: 호출당 <3초
- **캐시 적중률**: >60%
- **성공률**: >95% 유지

---

## 🏗️ 구조적 리팩토링 계획 (중/장기)

### 식별된 주요 문제점

#### 🚨 Critical Issues
1. **Import 시스템 문제**
   - 현재: 수동 경로 조작 및 importlib 사용
   - 위치: `agent1.py`, `agent2.py`, `templates.py` 등 12+ 파일
   - 해결책: 적절한 패키지 import와 `__init__.py` 파일

2. **God Object 안티패턴**
   - Agent1: 1,279줄 (변수 추출, 의도 분류, 대화 상태, 정책 검증)
   - Agent2: 1,008줄 (템플릿 생성, 산업 분류, 도구 조정, 캐싱)
   - 해결책: 단일 책임 원칙에 따른 클래스 분해

3. **설정 시스템 분산**
   - 3개의 경쟁하는 설정 시스템
   - `config.legacy`, `config.settings`, `config.llm_providers`
   - 해결책: 통합된 설정 시스템

#### ⚠️ Important Issues
4. **순환 의존성 위험**: 복잡한 교차 모듈 의존성
5. **오류 처리 불일치**: 중앙화된 오류 처리 전략 부재
6. **계층간 강한 결합**: API가 비즈니스 로직 직접 인스턴스화

### 리팩토링 로드맵

#### Phase 1: Import 시스템 안정화 (Critical)
```python
# 현재 문제
import importlib.util
spec = importlib.util.spec_from_file_location("variable_extractor",
    project_root / "app" / "tools" / "variable_extractor.py")

# 목표 상태
from app.tools.variable_extractor import VariableExtractor
```
- **시간**: 1-2주
- **우선순위**: 최고
- **의존성**: 없음

#### Phase 2: 서비스 레이어 추출 (Critical)
```python
# 목표 아키텍처
class ILLMProvider(ABC):
    async def generate(self, prompt: str) -> str: pass

class ITemplateGenerator(ABC):
    async def generate_template(self, input_data: dict) -> Template: pass

class IDataManager(ABC):
    async def get_templates(self, query: str) -> List[Template]: pass
```
- **시간**: 3-4주
- **우선순위**: 높음
- **의존성**: Phase 1 완료

#### Phase 3: Agent 클래스 분해 (Important)
**Agent1 분해:**
```python
- ConversationManager (상태 관리)
- InputValidator (비속어/언어 검사)
- VariableProcessor (추출 및 분석)
- DialogueController (플로우 제어)
```

**Agent2 분해:**
```python
- TemplateGenerator (핵심 생성 로직)
- IndustryClassifier (분류 로직)
- ComplianceChecker (블랙리스트/화이트리스트/법적)
- DataCacheManager (캐싱 작업)
```
- **시간**: 4-6주
- **우선순위**: 보통
- **의존성**: Phase 2 완료

#### Phase 4: 설정 시스템 통합 (Important)
```python
config/
├── __init__.py
├── base.py          # 기본 설정 클래스
├── development.py   # 개발 설정
├── production.py    # 운영 설정
└── providers.py     # LLM 제공자 설정
```
- **시간**: 1-2주
- **우선순위**: 보통
- **의존성**: Phase 1 완료

#### Phase 5: 오류 처리 구현 (Medium)
- 사용자 정의 예외 계층
- 중앙화된 오류 로깅
- 표준화된 API 오류 응답
- 외부 서비스를 위한 회로 차단기 패턴
- **시간**: 2-3주
- **우선순위**: 낮음
- **의존성**: Phase 2 완료

---

## 🌐 LangGraph 마이그레이션 계획

### LangGraph 적합성 평가: ✅ 권장

#### 주요 이유
1. **복잡한 상태 관리**: 다중 턴 대화에서 변수 수집
2. **조건부 라우팅**: Agent1의 여러 검증 단계
3. **도구 오케스트레이션**: Agent2의 4개 도구 병렬 실행
4. **오류 처리**: 여러 실패 모드에 대한 복구 경로

### 구현 전략

#### LangGraph 아키텍처 예시
```python
from langgraph.graph import StateGraph, START, END
from typing import TypedDict

class JoberState(TypedDict):
    user_input: str
    variables: dict
    conversation_context: str
    validation_status: str
    template_result: dict
    error_messages: list
    reask_count: int

def agent1_validate(state: JoberState) -> JoberState:
    # 기존 Agent1 로직
    pass

def check_completeness(state: JoberState) -> str:
    if state['validation_status'] == 'complete':
        return 'generate_template'
    elif state['reask_count'] < 3:
        return 'reask_variables'
    else:
        return 'max_reask_error'

# 그래프 구축
workflow = StateGraph(JoberState)
workflow.add_node("validate_input", agent1_validate)
workflow.add_node("generate_template", agent2_generate)
workflow.add_conditional_edges(
    "validate_input",
    check_completeness,
    {
        "generate_template": "generate_template",
        "reask_variables": "reask_variables",
        "max_reask_error": END
    }
)
```

### 마이그레이션 단계

#### Phase 1: 개념 증명 (3주)
- 핵심 Agent1→Agent2 플로우의 LangGraph 버전
- 기본 상태 관리 구현
- 현재 시스템과 성능 비교

#### Phase 2: 프로덕션 마이그레이션 (4-6주)
- 기존 시스템의 점진적 교체
- 구/신 구현 간 A/B 테스트
- 성능 최적화

#### Phase 3: 고급 기능 (2-3주)
- 고급 재시도 로직
- 에지 케이스를 위한 향상된 human-in-the-loop
- 모니터링 및 분석 통합

### 예상 효과
- **대화 상태 버그 30% 감소**
- **새로운 에이전트 기능 추가 50% 용이**
- **향상된 오류 복구** 메커니즘
- **프로덕션 디버깅을 위한 관찰 가능성 개선**

### 전제 조건
1. **팀 훈련**: 개발팀을 위한 1주간 LangGraph 학습
2. **테스트 인프라**: 상태 기반 워크플로우를 위한 향상된 테스트
3. **모니터링 설정**: LangGraph 워크플로우를 위한 관찰 도구
4. **대체 전략**: 마이그레이션 중 백업으로 현재 시스템 유지

---

## 📅 전체 구현 타임라인

### 즉시 (1-2주) - 성능 최적화 Phase 1
- [ ] Agent2 도구 병렬화
- [ ] Agent1 병렬 처리
- [ ] 기본 LLM 연결 풀링
- **목표**: 40% 성능 향상 (15-20초 → 8-12초)

### 단기 (1개월) - 성능 목표 달성
- [ ] 고급 LLM 최적화
- [ ] 템플릿 캐싱 시스템
- [ ] Chroma DB 비동기 작업
- **목표**: 60% 성능 향상 달성 (5-10초)

### 중기 (2-3개월) - 구조적 안정화
- [ ] Import 시스템 수정
- [ ] 서비스 레이어 추출
- [ ] Agent 클래스 분해 시작
- [ ] LangGraph 개념 증명

### 장기 (3-6개월) - 아키텍처 현대화
- [ ] LangGraph 프로덕션 마이그레이션
- [ ] 완전한 Agent 리팩토링
- [ ] 고급 성능 최적화
- [ ] 종합적인 모니터링 시스템

## 🎯 성공 지표

### 성능 지표
- **응답 시간**: 10-20초 → 5-10초 (60% 개선)
- **Agent1 시간**: 2-5초 → <2초
- **Agent2 시간**: 8-15초 → <5초
- **LLM 지연**: 호출당 <3초
- **캐시 적중률**: >60%

### 품질 지표
- **성공률**: >95% 유지
- **오류율**: <5%
- **코드 품질**: 클래스당 <200줄
- **테스트 커버리지**: >80%

### 유지보수성 지표
- **평균 클래스 크기**: 400+ LOC → <200 LOC
- **Import 복잡성**: 높음 (수동) → 낮음 (표준)
- **결합 수준**: 긴밀 → 느슨
- **설정 시스템**: 3개 경쟁 → 1개 통합

## 📞 다음 단계
1. **즉시**: Agent2 도구 병렬화 구현 시작
2. **이번 주**: Agent1 병렬 처리 계획 수립
3. **다음 주**: LLM 최적화 전략 구현
4. **2주 후**: Phase 1 성능 향상 검증 및 Phase 2 계획

**우선순위**: 성능 최적화를 먼저 완료한 후 구조적 리팩토링 진행
**목표**: 5-10초 응답 시간을 달성하고 장기적으로 유지 가능한 아키텍처 구축