#!/usr/bin/env python3
"""
LangGraph 통합 - 기존 API와 LangGraph 워크플로우 통합

백엔드 API 호환성 100% 유지하면서 LangGraph 워크플로우 적용
"""

import time
import uuid
from typing import Dict, Any, Optional, Tuple
from fastapi.responses import JSONResponse

from app.core.langgraph_state import (
    JoberState, ProcessingStatus, TemplateSource,
    initialize_jober_state, convert_to_api_response
)
from app.core.langgraph_workflow import create_jober_workflow
from app.utils.performance_logger import get_performance_logger


class LangGraphTemplateProcessor:
    """
    LangGraph 기반 템플릿 처리기

    기존 API 인터페이스를 유지하면서 내부적으로 LangGraph 워크플로우 사용
    """

    def __init__(self):
        self.workflow = create_jober_workflow()
        self.perf_logger = get_performance_logger()

    async def process_template_request(
        self,
        user_id: int,
        request_content: str,
        conversation_context: Optional[str] = None
    ) -> Tuple[Dict[str, Any], float, Dict[str, Any]]:
        """
        템플릿 요청 처리 (LangGraph 워크플로우 사용)

        Args:
            user_id: 사용자 ID
            request_content: 요청 내용
            conversation_context: 대화 컨텍스트

        Returns:
            Tuple[결과, 처리시간, 메타데이터]
        """
        request_id = str(uuid.uuid4())[:8]
        start_time = time.time()

        print(f"LangGraph 워크플로우 시작: {request_id}")

        try:
            # 1. 초기 상태 생성
            initial_state = initialize_jober_state(
                user_input=request_content,
                conversation_context=conversation_context,
                user_id=user_id
            )

            # 2. LangGraph 워크플로우 실행
            print(f"워크플로우 실행 중... (Request: {request_id})")
            final_state = await self.workflow.ainvoke(initial_state)

            # 3. 처리 시간 계산
            total_time = time.time() - start_time

            # 4. 성능 로깅
            self._log_performance(request_id, user_id, request_content, final_state, total_time)

            # 5. 백엔드 API 호환 형식으로 변환
            api_response = convert_to_api_response(final_state)

            # 6. 메타데이터 구성
            metadata = {
                "request_id": request_id,
                "workflow_path": final_state.get("workflow_path", []),
                "processing_times": final_state.get("processing_times", {}),
                "status": final_state.get("status"),
                "langgraph_enabled": True,
                "performance_improvement": self._calculate_improvement(final_state)
            }

            print(f"LangGraph 워크플로우 완료: {request_id} ({total_time:.2f}초)")

            return api_response, total_time, metadata

        except Exception as e:
            error_time = time.time() - start_time
            print(f"LangGraph 워크플로우 실패: {request_id} ({error_time:.2f}초) - {e}")

            # 오류 응답 생성
            error_response = {
                "success": False,
                "error": f"LangGraph 워크플로우 오류: {str(e)}",
                "error_code": "LANGGRAPH_WORKFLOW_ERROR"
            }

            metadata = {
                "request_id": request_id,
                "error": str(e),
                "langgraph_enabled": True,
                "fallback_used": False
            }

            return error_response, error_time, metadata

    def _log_performance(self, request_id: str, user_id: int, request_content: str, final_state: JoberState, total_time: float):
        """성능 로깅"""
        try:
            processing_times = final_state.get("processing_times", {})
            workflow_path = final_state.get("workflow_path", [])

            # 단계별 시간 분석
            stage_breakdown = {
                "validation": processing_times.get("validation", 0.0),
                "variable_extraction": processing_times.get("variable_extraction", 0.0),
                "policy_check": processing_times.get("policy_check", 0.0),
                "template_selection": processing_times.get("template_selection", 0.0),
                "template_generation": processing_times.get("template_generation", 0.0),
                "compliance_validation": processing_times.get("compliance_validation", 0.0)
            }

            self.perf_logger.log_request_timing(
                request_id=request_id,
                user_id=user_id,
                request_content=request_content,
                total_time=total_time,
                stage_times=stage_breakdown,
                metadata={
                    "workflow_type": "langgraph",
                    "workflow_path": workflow_path,
                    "final_status": final_state.get("status"),
                    "template_source": final_state.get("template_source"),
                    "completion_percentage": final_state.get("completion_percentage", 0.0)
                }
            )

            print(f" 성능 로그 기록: {request_id}")

        except Exception as e:
            print(f"성능 로깅 실패: {e}")

    def _calculate_improvement(self, final_state: JoberState) -> Dict[str, Any]:
        """성능 개선 계산"""
        try:
            processing_times = final_state.get("processing_times", {})
            total_time = processing_times.get("total", 0.0)

            # 예상 순차 처리 시간 (기존 방식)
            estimated_sequential = {
                "validation": processing_times.get("validation", 0.0) * 1.5,  # 병렬 처리 효과
                "variable_extraction": processing_times.get("variable_extraction", 0.0) * 1.3,
                "template_generation": processing_times.get("template_generation", 0.0) * 2.0,  # Agent2 병렬 효과
                "other": sum([
                    processing_times.get("policy_check", 0.0),
                    processing_times.get("template_selection", 0.0),
                    processing_times.get("compliance_validation", 0.0)
                ])
            }

            estimated_total = sum(estimated_sequential.values())
            improvement_ratio = ((estimated_total - total_time) / estimated_total) * 100 if estimated_total > 0 else 0

            return {
                "actual_time": total_time,
                "estimated_sequential_time": estimated_total,
                "improvement_percentage": round(improvement_ratio, 1),
                "time_saved": round(estimated_total - total_time, 2),
                "parallel_optimizations": {
                    "validation_parallel": True,
                    "agent2_tools_parallel": True,
                    "workflow_optimization": True
                }
            }

        except Exception as e:
            print(f"성능 개선 계산 실패: {e}")
            return {"error": str(e)}


class LangGraphAPIResponseConverter:
    """
    LangGraph 결과를 기존 API 응답 형식으로 변환

    백엔드 팀 코드 수정 없이 호환성 보장
    """

    @staticmethod
    def convert_to_template_response(api_response: Dict[str, Any], metadata: Dict[str, Any]) -> Dict[str, Any]:
        """LangGraph 결과를 템플릿 API 응답으로 변환"""

        if not api_response.get("success", False):
            # 오류 응답 처리
            error_code = api_response.get("error_code", "UNKNOWN_ERROR")
            error_message = api_response.get("error", "알 수 없는 오류가 발생했습니다.")

            return {
                "success": False,
                "error_code": error_code,
                "message": error_message,
                "metadata": metadata
            }

        # 성공 응답 처리
        template_data = api_response.get("data", {})

        # 기존 API 형식에 맞게 변환
        converted_response = {
            "success": True,
            "data": template_data,
            "processing_time": metadata.get("total_time", 0.0),
            "template_source": metadata.get("template_source", "generated"),
            "langgraph_metadata": {
                "workflow_enabled": True,
                "performance_improvement": metadata.get("performance_improvement", {}),
                "workflow_path": metadata.get("workflow_path", [])
            }
        }

        return converted_response

    @staticmethod
    def convert_to_partial_response(api_response: Dict[str, Any], metadata: Dict[str, Any]) -> JSONResponse:
        """부분 완성 응답 변환 (202 상태코드)"""

        # 부분 완성 데이터 추출
        template_data = api_response.get("data", {})

        # 202 응답 생성
        return JSONResponse(
            status_code=202,
            content={
                "success": True,
                "status": "partial_completion",
                "data": template_data,
                "completion_percentage": api_response.get("completion_percentage", 0.0),
                "missing_variables": template_data.get("variables", []),
                "langgraph_metadata": {
                    "workflow_enabled": True,
                    "processing_time": metadata.get("total_time", 0.0)
                }
            }
        )

    @staticmethod
    def convert_error_response(api_response: Dict[str, Any], metadata: Dict[str, Any], status_code: int = 400) -> JSONResponse:
        """오류 응답 변환"""

        error_content = {
            "success": False,
            "error": {
                "code": api_response.get("error_code", "UNKNOWN_ERROR"),
                "message": api_response.get("error", "알 수 없는 오류가 발생했습니다.")
            },
            "langgraph_metadata": {
                "workflow_enabled": True,
                "request_id": metadata.get("request_id", "unknown"),
                "processing_time": metadata.get("total_time", 0.0)
            }
        }

        return JSONResponse(
            status_code=status_code,
            content=error_content
        )


# 전역 프로세서 인스턴스 (싱글톤 패턴)
_langgraph_processor = None


def get_langgraph_processor() -> LangGraphTemplateProcessor:
    """LangGraph 프로세서 싱글톤 인스턴스 반환"""
    global _langgraph_processor

    if _langgraph_processor is None:
        print("LangGraph 프로세서 초기화 중...")
        _langgraph_processor = LangGraphTemplateProcessor()
        print("LangGraph 프로세서 초기화 완룼")

    return _langgraph_processor


async def process_template_with_langgraph(
    user_id: int,
    request_content: str,
    conversation_context: Optional[str] = None
) -> Tuple[Dict[str, Any], float, Dict[str, Any]]:
    """
    LangGraph를 사용한 템플릿 처리 (편의 함수)

    Args:
        user_id: 사용자 ID
        request_content: 요청 내용
        conversation_context: 대화 컨텍스트

    Returns:
        Tuple[API 응답, 처리시간, 메타데이터]
    """
    processor = get_langgraph_processor()
    return await processor.process_template_request(
        user_id=user_id,
        request_content=request_content,
        conversation_context=conversation_context
    )


def is_langgraph_enabled() -> bool:
    """LangGraph 활성화 여부 확인"""
    try:
        # 환경 변수나 설정 파일에서 확인 가능
        # 현재는 항상 활성화
        return True
    except Exception:
        return False