#!/usr/bin/env python3
"""
í•œêµ­ì–´ í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ (KoNLPy ê¸°ë°˜)
Issue 5 í•´ê²°: ë¬´ì˜ë¯¸í•œ ì…ë ¥ í…œí”Œë¦¿ ìƒì„± ë¬¸ì œ - 2ë‹¨ê³„ í•œêµ­ì–´ í’ˆì§ˆ ê²€ì¦
"""
import re
from typing import Tuple, List, Dict
from enum import Enum

class KoreanValidationError(Enum):
    """í•œêµ­ì–´ ê²€ì¦ ì˜¤ë¥˜ íƒ€ì…"""
    JAMO_ONLY = "JAMO_ONLY"  # ììŒ/ëª¨ìŒë§Œ ìˆìŒ
    NO_MEANINGFUL_WORDS = "NO_MEANINGFUL_WORDS"  # ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ ì—†ìŒ
    LOW_WORD_RATIO = "LOW_WORD_RATIO"  # ë‹¨ì–´ ë¹„ìœ¨ ë„ˆë¬´ ë‚®ìŒ
    NONSENSE_PATTERN = "NONSENSE_PATTERN"  # ë¬´ì˜ë¯¸í•œ íŒ¨í„´
    INCOMPLETE_WORDS = "INCOMPLETE_WORDS"  # ë¶ˆì™„ì „í•œ ë‹¨ì–´ë“¤
    VALID = "VALID"

class KoreanValidator:
    """KoNLPy ê¸°ë°˜ í•œêµ­ì–´ í’ˆì§ˆ ê²€ì¦ í´ë˜ìŠ¤"""

    def __init__(self):
        """í•œêµ­ì–´ ê²€ì¦ê¸° ì´ˆê¸°í™”"""
        self.okt = None
        self._init_morphological_analyzer()
        self._init_korean_dictionaries()

        # ê²€ì¦ ì„ê³„ê°’ë“¤
        self.min_meaningful_word_ratio = 0.3  # ìµœì†Œ ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ ë¹„ìœ¨ 30%
        self.min_word_count = 1  # ìµœì†Œ ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ ê°œìˆ˜
        self.max_jamo_ratio = 0.5  # ìµœëŒ€ ììŒ/ëª¨ìŒ ë¹„ìœ¨ 50%

        print("ğŸ” í•œêµ­ì–´ í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    def _init_morphological_analyzer(self):
        """í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™” (ì§€ì—° ë¡œë”©)"""
        try:
            from konlpy.tag import Okt
            self.okt = Okt()
            print("âœ… KoNLPy í˜•íƒœì†Œ ë¶„ì„ê¸° ë¡œë“œ ì™„ë£Œ")
        except ImportError:
            print("âš ï¸ KoNLPyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ê²€ì¦ ëª¨ë“œë¡œ ë™ì‘")
            self.okt = None
        except Exception as e:
            print(f"âš ï¸ í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.okt = None

    def _init_korean_dictionaries(self):
        """í•œêµ­ì–´ ì‚¬ì „ ë° íŒ¨í„´ ì´ˆê¸°í™”"""
        # ê¸°ë³¸ í•œêµ­ì–´ ë‹¨ì–´ ì‚¬ì „ (ì•Œë¦¼í†¡ ë„ë©”ì¸ íŠ¹í™”)
        self.basic_korean_words = {
            # ì•Œë¦¼í†¡ í•µì‹¬ í‚¤ì›Œë“œ
            'ì˜ˆì•½', 'í™•ì¸', 'ì•ˆë‚´', 'ì•Œë¦¼', 'ê³µì§€', 'ë³€ê²½', 'ì·¨ì†Œ', 'ì™„ë£Œ',
            'ê²°ì œ', 'ì£¼ë¬¸', 'ë°°ì†¡', 'ë°œì†¡', 'ë„ì°©', 'ì¶œë°œ', 'ì ‘ìˆ˜',
            'íšŒì›', 'ê°€ì…', 'ë“±ë¡', 'ì‹ ì²­', 'ì°¸ê°€', 'ì°¸ì—¬', 'ì´ìš©',
            'í• ì¸', 'í˜œíƒ', 'ì¿ í°', 'í¬ì¸íŠ¸', 'ì ë¦½', 'ì‚¬ìš©', 'ë§Œë£Œ',
            'ì´ë²¤íŠ¸', 'í–‰ì‚¬', 'ëª¨ì„', 'ë§Œë‚¨', 'ë°©ë¬¸', 'ì‹œê°„', 'ì¥ì†Œ',
            'ê³ ê°', 'ë‹˜', 'ë¶„', 'ì”¨', 'ì„ ìƒë‹˜', 'ì‚¬ì¥ë‹˜', 'íšŒì›ë‹˜',

            # ê¸°ë³¸ ëª…ì‚¬ë“¤
            'ì¹´í˜', 'ì‹ë‹¹', 'ë³‘ì›', 'í•™ì›', 'íšŒì‚¬', 'í•™êµ', 'ì§‘', 'ì‚¬ë¬´ì‹¤',
            'ìƒí’ˆ', 'ì„œë¹„ìŠ¤', 'ì œí’ˆ', 'ë¬¼í’ˆ', 'ìƒí™©', 'ë¬¸ì œ', 'í•´ê²°',
            'ì—°ë½', 'ì „í™”', 'ë©”ì‹œì§€', 'ë¬¸ì', 'ì´ë©”ì¼', 'í™ˆí˜ì´ì§€',
            'ì˜¤ëŠ˜', 'ë‚´ì¼', 'ì–´ì œ', 'ì‹œê°„', 'ë‚ ì§œ', 'ì£¼ë§', 'í‰ì¼',

            # ê¸°ë³¸ ë™ì‚¬/í˜•ìš©ì‚¬ ì–´ê°„
            'ë³´ë‚´', 'ë°›', 'ë“œë¦¬', 'ì£¼', 'í•´', 'ë˜', 'ìˆ', 'ì—†', 'ê°™', 'ë‹¤ë¥¸',
            'ì¢‹', 'ë‚˜ì˜', 'ì¤‘ìš”', 'í•„ìš”', 'ê°€ëŠ¥', 'ë¶ˆê°€ëŠ¥', 'í¸ë¦¬', 'ì•ˆì „'
        }

        # ë¬´ì˜ë¯¸í•œ íŒ¨í„´ë“¤
        self.nonsense_patterns = [
            r'^ã…‹+$',  # ã…‹ã…‹ã…‹
            r'^ã…+$',  # ã…ã…ã…
            r'^ã… +$',  # ã… ã… ã… 
            r'^ã…œ+$',  # ã…œã…œã…œ
            r'^[ã…-ã…£]+$',  # ëª¨ìŒë§Œ
            r'^[ã„±-ã…]+$',  # ììŒë§Œ
            r'^[ã…-ã…£ã„±-ã…]+$',  # ììŒëª¨ìŒ ì¡°í•©ë§Œ
        ]

        # ë¶ˆì™„ì „í•œ í•œê¸€ íŒ¨í„´ (ììŒ/ëª¨ìŒ í˜¼ì¬)
        self.incomplete_hangul_patterns = [
            r'[ã„±-ã…ã…-ã…£]',  # ììŒì´ë‚˜ ëª¨ìŒì´ ë‹¨ë…ìœ¼ë¡œ ì¡´ì¬
        ]

    def detect_jamo_ratio(self, text: str) -> float:
        """ììŒ/ëª¨ìŒ ë‹¨ë… ë¬¸ì ë¹„ìœ¨ ê³„ì‚°"""
        if not text:
            return 0.0

        # ììŒ/ëª¨ìŒ íŒ¨í„´ (ì™„ì„±ë˜ì§€ ì•Šì€ í•œê¸€)
        jamo_count = len(re.findall(r'[ã„±-ã…ã…-ã…£]', text))
        total_korean = len(re.findall(r'[ê°€-í£ã„±-ã…ã…-ã…£]', text))

        return jamo_count / total_korean if total_korean > 0 else 0.0

    def check_nonsense_patterns(self, text: str) -> bool:
        """ë¬´ì˜ë¯¸í•œ íŒ¨í„´ ê²€ì‚¬"""
        text_clean = re.sub(r'\s+', '', text.strip())

        for pattern in self.nonsense_patterns:
            if re.match(pattern, text_clean):
                return True
        return False

    def extract_meaningful_words_fallback(self, text: str) -> List[str]:
        """í´ë°±: KoNLPy ì—†ì„ ë•Œ ê¸°ë³¸ ë‹¨ì–´ ì¶”ì¶œ"""
        meaningful_words = []

        # ê¸°ë³¸ ì‚¬ì „ì—ì„œ ì°¾ê¸°
        for word in self.basic_korean_words:
            if word in text:
                meaningful_words.append(word)

        # í•œê¸€ 2ì ì´ìƒ ë‹¨ì–´ ì¶”ì¶œ (íœ´ë¦¬ìŠ¤í‹±)
        korean_words = re.findall(r'[ê°€-í£]{2,}', text)
        meaningful_words.extend(korean_words)

        return list(set(meaningful_words))

    def extract_meaningful_words_konlpy(self, text: str) -> List[str]:
        """KoNLPy ê¸°ë°˜ ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ ì¶”ì¶œ"""
        try:
            # í˜•íƒœì†Œ ë¶„ì„
            morphs = self.okt.morphs(text)
            pos_tags = self.okt.pos(text)
            nouns = self.okt.nouns(text)

            meaningful_words = []

            # 1. ëª…ì‚¬ (2ê¸€ì ì´ìƒ)
            meaningful_nouns = [noun for noun in nouns if len(noun) >= 2]
            meaningful_words.extend(meaningful_nouns)

            # 2. ì˜ë¯¸ìˆëŠ” í’ˆì‚¬ (ë™ì‚¬, í˜•ìš©ì‚¬, ë¶€ì‚¬)
            meaningful_pos = ['Verb', 'Adjective', 'Adverb']
            for morph, pos in pos_tags:
                if pos in meaningful_pos and len(morph) >= 2:
                    meaningful_words.append(morph)

            # 3. ê¸°ë³¸ ì‚¬ì „ê³¼ êµì°¨ í™•ì¸
            for word in self.basic_korean_words:
                if word in text:
                    meaningful_words.append(word)

            return list(set(meaningful_words))

        except Exception as e:
            print(f"âš ï¸ KoNLPy ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return self.extract_meaningful_words_fallback(text)

    def extract_meaningful_words(self, text: str) -> List[str]:
        """ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ ì¶”ì¶œ (KoNLPy ìš°ì„ , í´ë°± ì§€ì›)"""
        if self.okt:
            return self.extract_meaningful_words_konlpy(text)
        else:
            return self.extract_meaningful_words_fallback(text)

    def calculate_word_quality_score(self, text: str) -> Dict:
        """ë‹¨ì–´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        if not text or not text.strip():
            return {
                'meaningful_words': [],
                'word_count': 0,
                'total_morphs': 0,
                'word_ratio': 0.0,
                'quality_score': 0.0
            }

        # ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ ì¶”ì¶œ
        meaningful_words = self.extract_meaningful_words(text)

        # ì „ì²´ í˜•íƒœì†Œ ê°œìˆ˜ (KoNLPyê°€ ìˆìœ¼ë©´ ì •í™•íˆ, ì—†ìœ¼ë©´ ì¶”ì •)
        if self.okt:
            try:
                total_morphs = len(self.okt.morphs(text))
            except:
                total_morphs = len(text.split())
        else:
            total_morphs = len(text.split())

        # ë¹„ìœ¨ ê³„ì‚°
        word_count = len(meaningful_words)
        word_ratio = word_count / total_morphs if total_morphs > 0 else 0.0

        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0.0 ~ 1.0)
        quality_score = min(word_ratio * 2, 1.0)  # 50% ë¹„ìœ¨ì´ë©´ ë§Œì 

        return {
            'meaningful_words': meaningful_words,
            'word_count': word_count,
            'total_morphs': total_morphs,
            'word_ratio': word_ratio,
            'quality_score': quality_score
        }

    def validate_korean_quality(self, text: str) -> Tuple[bool, KoreanValidationError, str]:
        """
        í•œêµ­ì–´ í’ˆì§ˆ ì¢…í•© ê²€ì¦

        Returns:
            Tuple[bool, KoreanValidationError, str]: (ìœ íš¨ì—¬ë¶€, ì˜¤ë¥˜íƒ€ì…, ì˜¤ë¥˜ë©”ì‹œì§€)
        """
        if not text or not text.strip():
            return False, KoreanValidationError.NO_MEANINGFUL_WORDS, "ì…ë ¥ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."

        text_clean = text.strip()

        # 1. ììŒ/ëª¨ìŒë§Œ ìˆëŠ”ì§€ í™•ì¸
        jamo_ratio = self.detect_jamo_ratio(text_clean)
        if jamo_ratio > self.max_jamo_ratio:
            return False, KoreanValidationError.JAMO_ONLY, f"ììŒ/ëª¨ìŒë§Œ ìˆëŠ” ì…ë ¥ì…ë‹ˆë‹¤ ({jamo_ratio:.1%}). ì™„ì„±ëœ í•œê¸€ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”."

        # 2. ë¬´ì˜ë¯¸í•œ íŒ¨í„´ í™•ì¸
        if self.check_nonsense_patterns(text_clean):
            return False, KoreanValidationError.NONSENSE_PATTERN, "ë¬´ì˜ë¯¸í•œ ë°˜ë³µ íŒ¨í„´ì…ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."

        # 3. ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ ë¶„ì„
        word_analysis = self.calculate_word_quality_score(text_clean)

        # 4. ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ ê°œìˆ˜ í™•ì¸
        if word_analysis['word_count'] < self.min_word_count:
            return False, KoreanValidationError.NO_MEANINGFUL_WORDS, f"ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤. êµ¬ì²´ì ì¸ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."

        # 5. ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ ë¹„ìœ¨ í™•ì¸
        if word_analysis['word_ratio'] < self.min_meaningful_word_ratio:
            return False, KoreanValidationError.LOW_WORD_RATIO, f"ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ ë¹„ìœ¨ì´ {word_analysis['word_ratio']:.1%}ë¡œ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤."

        # 6. ë¶ˆì™„ì „í•œ ë‹¨ì–´ í™•ì¸
        incomplete_count = len(re.findall(r'[ã„±-ã…ã…-ã…£]', text_clean))
        total_korean = len(re.findall(r'[ê°€-í£ã„±-ã…ã…-ã…£]', text_clean))
        if total_korean > 0 and incomplete_count / total_korean > 0.3:
            return False, KoreanValidationError.INCOMPLETE_WORDS, "ë¶ˆì™„ì „í•œ í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."

        # ëª¨ë“  ê²€ì¦ í†µê³¼
        return True, KoreanValidationError.VALID, "í•œêµ­ì–´ í’ˆì§ˆì´ ì–‘í˜¸í•©ë‹ˆë‹¤."

    def get_quality_suggestions(self, text: str, error_type: KoreanValidationError) -> str:
        """í’ˆì§ˆ ì˜¤ë¥˜ì— ë”°ë¥¸ ê°œì„  ì œì•ˆ"""
        suggestions = {
            KoreanValidationError.JAMO_ONLY: "ì˜ˆì‹œ: 'ã…ã„´ã…‡ã„¹' â†’ 'ì•ˆë‚´ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”'",
            KoreanValidationError.NO_MEANINGFUL_WORDS: "êµ¬ì²´ì ì¸ ì•Œë¦¼í†¡ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”. ì˜ˆ: 'ì˜ˆì•½ í™•ì¸', 'í• ì¸ ì•ˆë‚´' ë“±",
            KoreanValidationError.LOW_WORD_RATIO: "ë” ë§ì€ ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.",
            KoreanValidationError.NONSENSE_PATTERN: "ì˜ˆì‹œ: 'ã…‹ã…‹ã…‹' â†’ 'ì¬ë¯¸ìˆëŠ” ì´ë²¤íŠ¸ ì•ˆë‚´'",
            KoreanValidationError.INCOMPLETE_WORDS: "ì™„ì„±ëœ í•œê¸€ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”."
        }
        return suggestions.get(error_type, "ì˜¬ë°”ë¥¸ í•œêµ­ì–´ë¡œ ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    def analyze_korean_text(self, text: str) -> Dict:
        """í•œêµ­ì–´ í…ìŠ¤íŠ¸ ìƒì„¸ ë¶„ì„"""
        if not text:
            return {}

        analysis = {
            'jamo_ratio': self.detect_jamo_ratio(text),
            'has_nonsense_pattern': self.check_nonsense_patterns(text),
            'word_analysis': self.calculate_word_quality_score(text),
            'konlpy_available': self.okt is not None
        }

        # ê²€ì¦ ê²°ê³¼ ì¶”ê°€
        is_valid, error_type, message = self.validate_korean_quality(text)
        analysis['is_valid'] = is_valid
        analysis['error_type'] = error_type.value
        analysis['error_message'] = message

        return analysis


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)
_korean_validator = None

def get_korean_validator() -> KoreanValidator:
    """ì‹±ê¸€í†¤ í•œêµ­ì–´ ê²€ì¦ê¸° ë°˜í™˜"""
    global _korean_validator
    if _korean_validator is None:
        _korean_validator = KoreanValidator()
    return _korean_validator

# í¸ì˜ í•¨ìˆ˜ë“¤
def validate_korean_quality(text: str) -> Tuple[bool, KoreanValidationError, str]:
    """í•œêµ­ì–´ í’ˆì§ˆ ê²€ì¦ í¸ì˜ í•¨ìˆ˜"""
    validator = get_korean_validator()
    return validator.validate_korean_quality(text)

def extract_meaningful_words(text: str) -> List[str]:
    """ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ ì¶”ì¶œ í¸ì˜ í•¨ìˆ˜"""
    validator = get_korean_validator()
    return validator.extract_meaningful_words(text)

def is_quality_korean(text: str) -> bool:
    """ê°„ë‹¨í•œ í•œêµ­ì–´ í’ˆì§ˆ í™•ì¸"""
    valid, _, _ = validate_korean_quality(text)
    return valid


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ§ª í•œêµ­ì–´ í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    validator = KoreanValidator()

    # ë‹¤ì–‘í•œ í•œêµ­ì–´ í’ˆì§ˆ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    test_cases = [
        # ììŒ/ëª¨ìŒë§Œ ìˆëŠ” ì¼€ì´ìŠ¤
        "ã…ã„´ã…‡ã„¹",
        "ã…‹ã…‹ã…‹ã…‹",
        "ã… ã… ã… ",
        "ã„±ã„´ã„·ã„¹",

        # ë¬´ì˜ë¯¸í•œ íŒ¨í„´
        "ã…ã…ã…ã…ã…",
        "ã…ã…ã…ã…",

        # ë¶ˆì™„ì „í•œ í•œê¸€
        "ì•ˆë…•ã…ì„¸ìš”",
        "ì˜ˆì•½ã…‡ í™•ì¸",

        # í’ˆì§ˆì´ ë‚®ì€ í•œêµ­ì–´
        "ã…‡ì˜ˆì•½",
        "ì•ˆã„´ë‚´",

        # ì •ìƒì ì¸ í•œêµ­ì–´ (í†µê³¼í•´ì•¼ í•¨)
        "ì˜ˆì•½ í™•ì¸ ì•ˆë‚´",
        "í• ì¸ ì¿ í° ë°œê¸‰",
        "ì¹´í˜ ì˜ˆì•½ í™•ì¸ ë©”ì‹œì§€ ë§Œë“¤ì–´ì¤˜",
        "ê³ ê°ë‹˜ê»˜ ì—°ë½ë“œë¦¬ê² ìŠµë‹ˆë‹¤",
        "ë‚´ì¼ ì˜¤í›„ 2ì‹œ ë°©ë¬¸ ì˜ˆì •ì…ë‹ˆë‹¤",

        # í˜¼í•© ì¼€ì´ìŠ¤ (í•œêµ­ì–´ í¬í•¨)
        "John Smithë‹˜ ì˜ˆì•½ í™•ì¸",
        "010-1234-5678 ì—°ë½ì²˜ ì•ˆë‚´",
    ]

    for i, test_input in enumerate(test_cases, 1):
        print(f"\n{i:2d}. í…ŒìŠ¤íŠ¸: '{test_input}'")

        # ìƒì„¸ ë¶„ì„
        analysis = validator.analyze_korean_text(test_input)

        print(f"    ììŒ/ëª¨ìŒ ë¹„ìœ¨: {analysis.get('jamo_ratio', 0):.1%}")
        print(f"    ì˜ë¯¸ìˆëŠ” ë‹¨ì–´: {analysis.get('word_analysis', {}).get('meaningful_words', [])}")
        print(f"    ë‹¨ì–´ í’ˆì§ˆ ì ìˆ˜: {analysis.get('word_analysis', {}).get('quality_score', 0):.2f}")

        # ê²€ì¦ ê²°ê³¼
        is_valid = analysis.get('is_valid', False)
        status = "âœ… í†µê³¼" if is_valid else "âŒ ì°¨ë‹¨"
        message = analysis.get('error_message', '')
        print(f"    ê²°ê³¼: {status} - {message}")

        if not is_valid:
            error_type = KoreanValidationError(analysis.get('error_type', 'VALID'))
            suggestion = validator.get_quality_suggestions(test_input, error_type)
            print(f"    ì œì•ˆ: {suggestion}")

    print(f"\nğŸ”§ í•œêµ­ì–´ í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")